---
infrared_dir: "{{ ansible_user_dir }}/infrared"
infrared_workspaces_dir: "{{ ansible_user_dir }}/.infrared/.workspaces"
infrared_hosts_file: "{{ infrared_workspaces_dir }}/active/hosts"
instackenv_file: "{{ playbook_dir }}/instackenv.json"
undercloud_conf: "{{ ansible_user_dir }}/undercloud.conf"
log_directory: "{{ playbook_dir }}/jetpack/logs"
cloud_name: cloud00
lab_name: scale
ansible_ssh_pass: password
ansible_ssh_key: "{{ ansible_user_dir }}/.ssh/id_rsa"
osp_release: 13
osp_puddle: passed_phase2
controller_count: 3
# No need to set compute_count. This will be set to all remaining nodes, which is calclulated in overcloud.yml
#compute_count: 1
set_boot_order: false
hammer_host: hwstore.example.com

# Other lab machines have to define their interfaces through below
# 'interfaces' variable. prepare_nic_configs.yml will use that
# instead of deriving from
# scale/alias.machine_types.supermicro/dell...interfaces
# note: If you are using scale lab or alias lab, don't enable below
# 'interfaces' parameter.
#interfaces: []

#extra_templates:

# containers params
registry_mirror: redhat.com
registry_namespace: redhat
insecure_registries: redhat.com
# undercloud.conf default section
undercloud_public_host: 192.168.24.2
undercloud_admin_host: 192.168.24.3
# undercloud.conf ctlplane-subnet section config options
cidr: 192.168.24.0/24
gateway: 192.168.24.1
dhcp_start: 192.168.24.5
dhcp_end: 192.168.24.105
inspection_iprange: 192.168.24.110,192.168.24.250
# external network params for adding external network to
# undercloud to access overcloud resources
external_gateway: 172.17.5.1/24
external_network_broadcast: 172.17.5.255
external_network_vlan_id: 300
clean_debug: False
#adding changes 
external_net_cidr: 172.17.5.0/24
external_allocation_pools_start: 172.17.5.50
external_allocation_pools_end: 172.17.5.150
external_interface_default_route: 172.17.5.1
#internal
internal_api_net_cidr: 172.17.1.0/24
internal_api_allocation_pools_start: 172.17.1.10
internal_api_allocation_pools_end: 172.17.1.149
internal_api_network_vlan_id: 301
#storage
storage_net_cidr: 172.17.3.0/24
storage_allocation_pools_start: 172.17.3.10
storage_allocation_pools_end: 172.17.3.149
storage_network_vlan_id: 302
storage_mgmt_net_cidr: 172.17.4.0/24
storage_mgmt_allocation_pools_start: 172.17.4.10
storage_mgmt_allocation_pools_end: 172.17.4.149
storage_mgmt_network_vlan_id: 303
#tenant
tenant_net_cidr: 172.17.2.0/24
tenant_allocation_pools_start: 172.17.2.10
tenant_allocation_pools_end: 172.17.2.150
tenant_network_vlan_id: 304
#This allows the user to force re provision undercloud
#default is false - not forced
force_reprovision: false
#This enables user to have a undercloud in VM
#NOTE: now the vm is created in the ansible host, so
#do not enable this while running from your desktop
virtual_uc: false
undercloud_host: 172.16.0.2
vm_external_interface: eth0
undercloud_local_interface: eth0
virtual_uc_ctlplane_interface: em1
# RHEL 7 image url
vm_image_url: https://url.corp.redhat.com/rhel-guest-image-7-6-210-x86-64-qcow2
# RHEL 8 image url
# vm_image_url: 'http://download.hosts.prod.upshift.rdu2.redhat.com/released/RHEL-8/8.1.0/BaseOS/x86_64/images/rhel-guest-image-8.1-263.x86_64.qcow2'
#Neutron backend, if not set default will be used.
#neutron_backend: ovn
